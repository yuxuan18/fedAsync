{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import math\n",
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "num_clients = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10          # Total Bandwidth, kHz\n",
    "N_0 = -100      # Noise Spectrum Power Density\n",
    "h = -117        # Channel Gain\n",
    "SNR = 20        # Assumed SNR\n",
    "m = 1.2         # Model Size, Mb\n",
    "epsilon = 1     # Effective Capacitance Parameter of CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma = 1       # Training time constraint constant\n",
    "# rho = 1         # Staleness Decay\n",
    "tau = 1         # Time Length of Epoch\n",
    "lbd = 0.7       # Reputation Update Weight, < 1\n",
    "psi = 0.3       # Uncertain Reputation Ratio, < 1\n",
    "w1 = 1\n",
    "w2 = 1\n",
    "w3 = 1          # Rank Weights\n",
    "w4 = 1\n",
    "w5 = 1\n",
    "phi = 1.03      # Expected Training Time Constant, > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "for i in list(model.state_dict().values()):\n",
    "    m += i.nelement()\n",
    "\n",
    "m = m * 4 /1000 / 1000  # in Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class client():\n",
    "    def __init__(self, index, p = 0.2, fq = 0.7):\n",
    "        self.p = p                  # parameter, transmission energy, \n",
    "        self.bw = 0                 # variable, allocated bandwidth, kHz\n",
    "        self.ts = -1                # parameter, time stamp, -1 -> not in a training\n",
    "        self.fq = fq                # parameter, local CPU frequency, GHz\n",
    "        self.c_i = 2 * m * 20 * 600 # number of CPU cycles to finish the training taskg\n",
    "        self.fn =  0                # parameter, fairness\n",
    "        self.rp = 0.8               # parameter, reputation\n",
    "        self.AoU = -1               # parameter, age of update\n",
    "        self.bf = 0                 # parameter, belief reputation\n",
    "        self.dbf = 0                # parameter, disbelief reputation\n",
    "        self.unc = 0                # parameter, uncertain reputation\n",
    "        self.R = 0                  # parameter, rank score\n",
    "        self.ds = 600               # parameter, data size\n",
    "        self.index = index          # index\n",
    "        self.T_comp = 0             # parameter, expected training time\n",
    "        self.c_n = 20               # number of iterations done in the local training\n",
    "        self.a = 0                  # parameter, coefficient over b in the formula of energy\n",
    "        self.worker = sy.VirtualWorker(hook, id= \"c\" + str(index))\n",
    "        self.local_model = model    # model returned after the local training\n",
    "        self.stale_model = model    # model received before the local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for i in range(num_clients):\n",
    "    clients.append(client(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The following options are not supported: num_workers: 1, pin_memory: True\n"
     ]
    }
   ],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "    .federate( tuple(ct.worker for ct in clients) ), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False,\n",
    "                    transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, federated_train_loader, optimizer, epoch, clients, index):\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "\n",
    "        if data.location != clients[index].worker: continue\n",
    "\n",
    "        \n",
    "\n",
    "        clients[index].stale_model = clients[index].local_model\n",
    "        clients[index].local_model.train()\n",
    "\n",
    "        clients[index].local_model.send(data.location) # <-- NEW: send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        time_start = time.time()\n",
    "        for _ in range(clients[index].c_n):\n",
    "            optimizer.zero_grad()\n",
    "            output = clients[index].local_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        time_end = time.time()\n",
    "\n",
    "        T_comp = 4*(time_end - time_start)\n",
    "        clients[index].T_comp = T_comp\n",
    "        \n",
    "        clients[index].local_model.get() # <-- NEW: get the model back\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        #     for key in model.state_dict().keys():\n",
    "        #         model.state_dict()[key] = model.state_dict()[key] + \\\n",
    "        #             clients[index].local_model.state_dict()[key] - \\ \n",
    "        #             stale_model.state_dict()[key]\n",
    "\n",
    "        # if batch_idx % args.log_interval == 0:\n",
    "        # loss = loss.get() # <-- NEW: get the loss back\n",
    "        print('Train Epoch: {} Client Index: {} Time: {}'.format(\n",
    "            epoch, index, T_comp))\n",
    "\n",
    "        return math.ceil(4 *(time_end - time_start)/epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return test_loss, correct/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateRank(RankList, clients, total_trained):\n",
    "    for rc in RankList:\n",
    "        max_T_comp = 2 * m * 20 * 600 / 0.5\n",
    "        min_T_comp = 2 * m * 20 * 600 / 1.0\n",
    "        T_comp = ( clients[rc[0]].c_i / clients[rc[0]].fq - min_T_comp - (min_T_comp + max_T_comp)/2 ) / (max_T_comp - min_T_comp)\n",
    "        clients[rc[0]].R = w1 * clients[rc[0]].rp + w2 * ( 1 / (1 + np.exp(-(clients[rc[0]].AoU - 7))) - 1)\\\n",
    "                        + w3  * ( 1 / (1 + np.exp(-0.2 * (total_trained/num_clients - clients[rc[0]].fn))) - 1)\\\n",
    "                        + w4 * T_comp + w5 * (clients[rc[0]].ds - 600) / 600\n",
    "        rc[1] = clients[rc[0]].R\n",
    "\n",
    "    RankList = sorted(RankList, key=lambda x:-x[1])\n",
    "\n",
    "    return RankList, clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine(WaitingCache, TrainingClients, clients, epoch):\n",
    "    Total_staleness = 0\n",
    "    for record in TrainingClients:\n",
    "        Total_staleness += max(clients[record[0]].T_comp - (epoch - clients[record[0]].ts), 0)\n",
    "    \n",
    "    Total_staleness += len(WaitingCache)\n",
    "\n",
    "    return pow(phi, Total_staleness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downlink(clients, d, RankList, TrainingClients, epoch, model):\n",
    "\n",
    "    Avai_BW = B / d\n",
    "    for i in RankList:\n",
    "        clients[i[0]].a = m * clients[i[0]].p / math.log(1 + SNR)\n",
    "\n",
    "    num_downlink = 0\n",
    "    \n",
    "    has_solution = 1\n",
    "    sum_sqrt_a_i = 0\n",
    "    for i in range(len(RankList)):\n",
    "        sum_sqrt_a_i += math.sqrt(clients[RankList[i][0]].a)\n",
    "        for j in range(i):\n",
    "            if sum_sqrt_a_i / math.sqrt(clients[RankList[j][0]].a) > tau * math.log(1 + SNR) * Avai_BW / m:\n",
    "                has_solution = 0\n",
    "                break\n",
    "\n",
    "        if has_solution == 0:\n",
    "            num_downlink = i\n",
    "            sum_sqrt_a_i -= math.sqrt(clients[RankList[i][0]].a)\n",
    "            break\n",
    "            \n",
    "        num_downlink = i + 1\n",
    "\n",
    "    Downlink_Bandwidth = []\n",
    "\n",
    "    print(\"num_DL:\", num_downlink)\n",
    "\n",
    "    count = 0\n",
    "    while count < num_downlink:\n",
    "        clients[RankList[0][0]].bw = Avai_BW * math.sqrt(clients[RankList[0][0]].a) / sum_sqrt_a_i\n",
    "        clients[RankList[0][0]].stale_model = model\n",
    "        Downlink_Bandwidth.append([RankList[0][0], clients[RankList[0][0]].bw])\n",
    "        clients[RankList[0][0]].ts = epoch\n",
    "        clients[RankList[0][0]].AoU = 0\n",
    "        clients[RankList[0][0]].fn += 1\n",
    "\n",
    "        remain_time = train(args, model, device, federated_train_loader, optimizer, epoch, clients, RankList[0][0])\n",
    "\n",
    "        #     for key in model.state_dict().keys():\n",
    "        #         model.state_dict()[key] = model.state_dict()[key] + \\\n",
    "        #             clients[index].local_model.state_dict()[key] - \\ \n",
    "        #             stale_model.state_dict()[key]\n",
    "\n",
    "        TrainingClients.append([RankList[0][0], epoch, remain_time + 1])\n",
    "        RankList.pop(0)\n",
    "        count+=1\n",
    "\n",
    "    # print(\"DL: RankList:\", RankList)\n",
    "\n",
    "    return clients, RankList, TrainingClients, Downlink_Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uplink(clients, d, WaitingCache, epoch, model):\n",
    "    Avai_BW = B * (1 - 1 / d)\n",
    "    for i in WaitingCache:\n",
    "        clients[i].a = m * clients[i].p / math.log(1 + SNR)\n",
    "\n",
    "    num_uplink = 0\n",
    "    \n",
    "    has_solution = 1\n",
    "    sum_sqrt_a_i = 0\n",
    "    for i in range(len(WaitingCache)):\n",
    "        sum_sqrt_a_i += math.sqrt(clients[WaitingCache[i]].a)\n",
    "        for j in range(i):\n",
    "            if sum_sqrt_a_i / math.sqrt(clients[WaitingCache[j]].a) > tau * math.log(1 + SNR) * Avai_BW / m:\n",
    "                has_solution = 0\n",
    "                break\n",
    "        if has_solution == 0:\n",
    "            num_uplink = i\n",
    "            sum_sqrt_a_i -= math.sqrt(clients[WaitingCache[i]].a)\n",
    "            break\n",
    "        num_uplink = i + 1\n",
    "\n",
    "    Uplink_Bandwidth = []\n",
    "\n",
    "    NewRankList = []\n",
    "\n",
    "    count = 0\n",
    "    while count < num_uplink:\n",
    "        clients[WaitingCache[0]].bw = Avai_BW * math.sqrt(clients[WaitingCache[0]].a) / sum_sqrt_a_i\n",
    "        Uplink_Bandwidth.append([WaitingCache[0], clients[WaitingCache[0]].bw])\n",
    "        clients[WaitingCache[0]].AoU = epoch - clients[WaitingCache[0]].ts\n",
    "        clients[WaitingCache[0]].ts = -1\n",
    "        NewRankList.append([WaitingCache[0], clients[WaitingCache[0]].R])\n",
    "        for key in model.state_dict().keys():\n",
    "            model.state_dict()[key] = (model.state_dict()[key] \\\n",
    "                                        + clients[WaitingCache[0]].local_model.state_dict()[key] \\\n",
    "                                        - clients[WaitingCache[0]].stale_model.state_dict()[key])\\\n",
    "                                        * pow(0.95, clients[WaitingCache[0]].AoU)\n",
    "        WaitingCache.pop(0)\n",
    "        count += 1\n",
    "\n",
    "    return clients, WaitingCache, NewRankList, Uplink_Bandwidth, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "RankList = [[i, clients[i].R] for i in range(num_clients)]\n",
    "WaitingCache = []\n",
    "TrainingClients = []\n",
    "test_loss = []\n",
    "accuracy = []\n",
    "num_uplink = []\n",
    "num_downlink = []\n",
    "total_trained = 0\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "\n",
    "    for ct in clients:\n",
    "        if ct.AoU != -1: ct.AoU += 1\n",
    "    Uplink = []\n",
    "    Downlink = []\n",
    "    NewRankList = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(TrainingClients):\n",
    "        TrainingClients[i][2] -= 1\n",
    "        if TrainingClients[i][2] <= 0:\n",
    "            WaitingCache.append(TrainingClients[i][0])\n",
    "            TrainingClients.pop(i)\n",
    "            continue\n",
    "        i+=1\n",
    "\n",
    "    d = determine(WaitingCache, TrainingClients, clients, epoch)\n",
    "\n",
    "    while 1:\n",
    "        if len(TrainingClients) > 0 and TrainingClients[0][1] >= epoch:\n",
    "            WaitingCache.append(TrainingClients[0][0])\n",
    "            TrainingClients.pop(0)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    RankList, clients = UpdateRank(RankList, clients, total_trained)\n",
    "\n",
    "    clients, WaitingCache, NewRankList, Uplink_Bandwidth, model = uplink(clients, d, WaitingCache, epoch, model)\n",
    "\n",
    "    clients, RankList, TrainingClients, Downlink_Bandwidth = downlink(clients, d, RankList, TrainingClients, epoch, model)\n",
    "\n",
    "    testloss, acc = test(args, model, device, test_loader)\n",
    "\n",
    "    total_trained = len(Downlink_Bandwidth)\n",
    "\n",
    "    test_loss.append(testloss)\n",
    "    accuracy.append(acc)\n",
    "\n",
    "    with open(\"Log.txt\", \"a\") as LOG:\n",
    "        LOG.write(\"Epoch = \" + str(epoch))\n",
    "        LOG.write(\"\\nd = \" + str(d))\n",
    "        LOG.write(\"\\nRankList = \" + str(RankList))\n",
    "        LOG.write(\"\\nUplink Available Bandwidth = \" + str(B * (1 - 1 / d)))\n",
    "        LOG.write(\"\\nDownlink Available Bandwidth = \" + str(B/d))\n",
    "        LOG.write(\"\\nUplink = [\" + str([i[0] for i in Uplink_Bandwidth]) + \"]\")\n",
    "        LOG.write(\"\\nDownlink = [\" + str([i[0] for i in Downlink_Bandwidth]) + \"]\\n\\n\")\n",
    "\n",
    "    print(\"Uplink: \", [i[0] for i in Uplink_Bandwidth])\n",
    "    print(\"Downlink: \", [i[0] for i in Downlink_Bandwidth])\n",
    "    num_uplink.append(len(Uplink_Bandwidth))\n",
    "    num_downlink.append(len(Downlink_Bandwidth))\n",
    "    \n",
    "\n",
    "    with open(\"Record.txt\", \"w\") as record:\n",
    "        for ct in clients:\n",
    "            rc = \"Index:\" + str(ct.index) + \" Bandwidth:\" + str(ct.bw) + \\\n",
    "                \" Rankscore:\" + str(ct.R) + \" Time Coefficient:\" + str(ct.a) + \"\\n\"\n",
    "            record.write(rc)\n",
    "    \n",
    "    for record in Uplink_Bandwidth:\n",
    "        clients[record[0]].bw = 0\n",
    "    for record in Downlink_Bandwidth: clients[record[0]].bw = 0\n",
    "\n",
    "    \n",
    "    RankList += NewRankList\n",
    "\n",
    "    RankList, clients = UpdateRank(RankList, clients, total_trained)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.title('Evolution of Test Loss')\n",
    "    plt.xlabel('Time Slot')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.plot(np.array(test_loss))\n",
    "    plt.savefig(\"test_loss.png\")\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Evolution of Accuracy')\n",
    "    plt.xlabel('Time Slot')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(np.array(accuracy))\n",
    "    plt.savefig(\"accuracy.png\")\n",
    "\n",
    "\n",
    "    if (args.save_model):\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
